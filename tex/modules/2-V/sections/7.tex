


\begin{applicationActivities}

\begin{observation}
  In the previous section, we learned that
  computing a basis for the subspace \(\vspan\{\vect v_1,\dots,\vect v_m\}\),
  is as simple as removing the vectors corresponding to the non-pivot columns of
  \(\RREF[\vect v_1\,\dots\,\vect v_m]\).

  \vspace{1em}

  For example, since
  \[
    \RREF
    \begin{bmatrix}
      1 & 2 & 3 \\
      0 & -2 & -2 \\
      -3 & 1 & -2
    \end{bmatrix}
      =
    \begin{bmatrix}
      \circledNumber{1} & 0 & 1 \\
      0 & \circledNumber{1} & 1 \\
      0 & 0 & 0
    \end{bmatrix}
  \]
  the subspace
  \(
    W=\vspan\setList{
      \begin{bmatrix}1\\0\\-3\end{bmatrix},
      \begin{bmatrix}2\\-2\\1\end{bmatrix},
      \begin{bmatrix}3\\-2\\-2\end{bmatrix}
    }
  \)
  has
  \(
    \setList{
      \begin{bmatrix}1\\0\\-3\end{bmatrix},
      \begin{bmatrix}2\\-2\\1\end{bmatrix}
    }
  \)
  as a basis.
\end{observation}

\begin{activity}{10}
  Let
  \begin{align*}
  S=\left\{
  \begin{bmatrix}2\\3\\0\\1\end{bmatrix},
  \begin{bmatrix}2\\0\\1\\-1\end{bmatrix},
  \begin{bmatrix}2\\-3\\2\\-3\end{bmatrix},
  \begin{bmatrix}1\\5\\-1\\0\end{bmatrix}
  \right\} & & \text{and}  & &
  T=\left\{
  \begin{bmatrix}2\\0\\1\\-1\end{bmatrix},
  \begin{bmatrix}2\\-3\\2\\-3\end{bmatrix},
  \begin{bmatrix}1\\5\\-1\\0\end{bmatrix},
  \begin{bmatrix}2\\3\\0\\1\end{bmatrix}
  \right\}
  \end{align*}
  \begin{subactivity}
  Find a basis for \(\vspan S\).
  \end{subactivity}
  \begin{subactivity}
  Find a basis for \(\vspan T\).
  \end{subactivity}
\end{activity}

\begin{observation}
  Even though we found different bases for them,
  \(\vspan S\) and \(\vspan T\) are exactly the same subspace of \(\IR^4\),
  since
  \[
    S=\left\{
    \begin{bmatrix}2\\3\\0\\1\end{bmatrix},
    \begin{bmatrix}2\\0\\1\\-1\end{bmatrix},
    \begin{bmatrix}2\\-3\\2\\-3\end{bmatrix},
    \begin{bmatrix}1\\5\\-1\\0\end{bmatrix}
    \right\}
      =
    \left\{
    \begin{bmatrix}2\\0\\1\\-1\end{bmatrix},
    \begin{bmatrix}2\\-3\\2\\-3\end{bmatrix},
    \begin{bmatrix}1\\5\\-1\\0\end{bmatrix},
    \begin{bmatrix}2\\3\\0\\1\end{bmatrix}
    \right\}=T
  \]
\end{observation}


\begin{fact}
  Any non-trivial vector space has infinitely-many different bases, but all
  the bases for a given vector space are exactly the same size.

  \vspace{1em}

  For example,
  \[
    \setList{\vec e_1,\vec e_2,\vec e_3}
      \text{ and }
    \setList{
      \begin{bmatrix}1\\0\\0\end{bmatrix},
      \begin{bmatrix}0\\1\\0\end{bmatrix},
      \begin{bmatrix}1\\1\\1\end{bmatrix}
    }
      \text{ and }
    \setList{
      \begin{bmatrix}1\\0\\-3\end{bmatrix},
      \begin{bmatrix}2\\-2\\1\end{bmatrix},
      \begin{bmatrix}3\\-2\\5\end{bmatrix}
    }
  \]
  are all valid bases for \(\IR^3\), and they all contain three vectors.
\end{fact}

\begin{definition}
  The \term{dimension} of a vector space is equal to the size
  of any basis for the vector space.

  \vspace{1em}

  As you'd expect, \(\IR^n\) has dimension \(n\).
  For example, \(\IR^3\) has dimension \(3\) because any basis for \(\IR^3\)
  such as
  \[
    \setList{\vec e_1,\vec e_2,\vec e_3}
      \text{ and }
    \setList{
      \begin{bmatrix}1\\0\\0\end{bmatrix},
      \begin{bmatrix}0\\1\\0\end{bmatrix},
      \begin{bmatrix}1\\1\\1\end{bmatrix}
    }
      \text{ and }
    \setList{
      \begin{bmatrix}1\\0\\-3\end{bmatrix},
      \begin{bmatrix}2\\-2\\1\end{bmatrix},
      \begin{bmatrix}3\\-2\\5\end{bmatrix}
    }
  \]
  contains exactly three vectors.
\end{definition}

\begin{activity}{10}
  Find the dimension of each subspace of \(\IR^4\) by finding
  \(\RREF\) for each corresponding matrix.

  \begin{center}
	\begin{tabular}{ll}

     \(\vspan\left\{
    \begin{bmatrix}2\\3\\0\\-1\end{bmatrix},
    \begin{bmatrix}2\\0\\0\\3\end{bmatrix},
    \begin{bmatrix}4\\3\\0\\2\end{bmatrix},
    \begin{bmatrix}-3\\0\\1\\3\end{bmatrix}
    \right\}
    \)

 &
     \(\vspan\left\{
    \begin{bmatrix}2\\3\\0\\-1\end{bmatrix},
    \begin{bmatrix}2\\0\\0\\3\end{bmatrix},
    \begin{bmatrix}3\\13\\7\\16\end{bmatrix},
    \begin{bmatrix}-1\\10\\7\\14\end{bmatrix},
    \begin{bmatrix}4\\3\\0\\2\end{bmatrix}
    \right\}
    \)
 \\
     \(\vspan\left\{
    \begin{bmatrix}2\\3\\0\\-1\end{bmatrix},
    \begin{bmatrix}4\\3\\0\\2\end{bmatrix},
    \begin{bmatrix}-3\\0\\1\\3\end{bmatrix},
    \begin{bmatrix}3\\6\\1\\5\end{bmatrix}
    \right\}
    \)

 &
     \(\vspan\left\{
    \begin{bmatrix}5\\3\\0\\-1\end{bmatrix},
    \begin{bmatrix}-2\\1\\0\\3\end{bmatrix},
    \begin{bmatrix}4\\5\\1\\3\end{bmatrix}
    \right\}
	\)
\end{tabular}
\end{center}
\end{activity}

\begin{fact}
  Every vector space with finite dimension, that is, every
  vector space \(V\) with a basis of the form
  \(\{\vect v_1,\vect v_2,\dots,\vect v_n\}\) is said to be
  \term{isomorphic} to a Euclidean space \(\IR^n\), since there exists
  a natural correspondance between vectors in \(V\) and vectors in \(\IR^n\):

  \[
    c_1\vect v_1+c_2\vect v_2+\dots+c_n\vect v_n
    \leftrightarrow
    \begin{bmatrix}
      c_1\\c_2\\\vdots\\c_n
    \end{bmatrix}
  \]
\end{fact}

\begin{observation}
  We've already been taking advantage of the previous fact by converting
  polynomials and matrices into Euclidean vectors. Since \(\P^3\)
  and \(M_{2,2}\) are both four-dimensional:

  \[
    4x^3+0x^2-1x+5
    \leftrightarrow
    \begin{bmatrix}
      4\\0\\-1\\5
    \end{bmatrix}
    \leftrightarrow
    \begin{bmatrix}
      4&0\\-1&5
    \end{bmatrix}
  \]
\end{observation}
%%TODO uncomment
%
%\begin{activity}{5}
%Suppose \(W\) is a subspace of \(\P^8\), and you know that
%% the set \(\{ x^3+x, x^2+1, x^4-x \}\) is a linearly independent subset of \(W\).
%it contains a \textbf{linearly independent} set of \(3\) vectors.
%What can you conclude about \(W\)?
%\begin{enumerate}[(a)]
%\item The dimension of \(W\) is at most 3.
%\item The dimension of \(W\) is exactly 3.
%\item The dimension of \(W\) is at least 3.
%\end{enumerate}
%\end{activity}
%
%\begin{activity}{5}
%Suppose \(W\) is a subspace of \(\P^8\), and you know that
%% \(W\) is spanned by the six vectors \[\{ x^4-x,x^3+x,x^3+x+1,x^4+2x,x^3,2x+1\}\]
%% Without doing any calculation,
%it contains a \textbf{spanning set} of \(3\) vectors.
%What can you conclude about \(W\)?
%\begin{enumerate}[(a)]
%\item The dimension of \(W\) is at most 3.
%\item The dimension of \(W\) is exactly 3.
%\item The dimension of \(W\) is at least 3.
%\end{enumerate}
%\end{activity}

\begin{observation}
  The space of polynomials \(\P\) (of \textit{any} degree)
  has the basis \(\{1,x,x^2,x^3,\dots\}\),
  so it is a natural example of an infinite-dimensional vector space.

  \vspace{1em}

  Since \(\P\) and other infinite-dimensional spaces cannot be treated as
  an isomorphic finite-dimensional Euclidean space \(\IR^n\), vectors in
  such spaces cannot be studied by converting them into Euclidean vectors.
  Fortunately, most of the examples we will be
  interested in for this course will be finite-dimensional.
\end{observation}

\begin{definition}
A \textbf{homogeneous} system of linear equations is one of the form:
  \begin{alignat*}{5}
    a_{11}x_1 &\,+\,& a_{12}x_2 &\,+\,& \dots  &\,+\,& a_{1n}x_n &\,=\,& 0 \\
    a_{21}x_1 &\,+\,& a_{22}x_2 &\,+\,& \dots  &\,+\,& a_{2n}x_n &\,=\,& 0 \\
     \vdots&  &\vdots&   &&  &\vdots&&\vdots  \\
    a_{m1}x_1 &\,+\,& a_{m2}x_2 &\,+\,& \dots  &\,+\,& a_{mn}x_n &\,=\,& 0
  \end{alignat*}

  This system is equivalent to the vector equation:
  \[x_1 \vec{v}_1 + \cdots+x_n \vec{v}_n = \vec{0}\]
  and the augmented matrix:
  \[
    \begin{bmatrix}[cccc|c]
      a_{11} & a_{12} & \cdots & a_{1n} & 0\\
      a_{21} & a_{22} & \cdots & a_{2n} & 0\\
      \vdots & \vdots & \ddots & \vdots & \vdots\\
      a_{m1} & a_{m2} & \cdots & a_{mn} & 0
    \end{bmatrix}
  \]
\end{definition}

\begin{activity}{5}
Note that if \(\begin{bmatrix} a_1 \\ \vdots \\ a_n \end{bmatrix} \) and
\(\begin{bmatrix} b_1 \\ \vdots \\ b_n \end{bmatrix} \) are solutions to
\(x_1 \vec{v}_1 + \cdots+x_n \vec{v}_n = \vec{0}\)
so is  \(\begin{bmatrix} a_1 +b_1\\ \vdots \\ a_n+b_n \end{bmatrix} \), since
\[a_1 \vec{v}_1+\cdots+a_n \vec{v}_n = \vec{0}
\text{ and }
b_1 \vec{v}_1+\cdots+b_n \vec{v}_n = \vec{0} \]
implies
\[(a_1 + b_1) \vec{v}_1+\cdots+(a_n+b_n) \vec{v}_n = \vec{0} .\]

Similarly, if \(c \in \IR\), \(\begin{bmatrix} ca_1 \\ \vdots \\ ca_n \end{bmatrix} \) is a solution.
Thus the solution set of a homogeneous system is...
\begin{multicols}{3}
\begin{enumerate}[a)]
  \item A basis for \(\IR^n\).
  \item A subspace of \(\IR^n\).
  \item The empty set.
\end{enumerate}
\end{multicols}
\end{activity}

\begin{activity}{10}
Consider the homogeneous system of equations
\begin{alignat*}{5}
x_1&\,+\,&2x_2&\,\,& &\,+\,& x_4 &=& 0 \\
2x_1&\,+\,&4x_2&\,-\,&x_3 &\,-\,&2 x_4 &=& 0 \\
3x_1&\,+\,&6x_2&\,-\,&x_3 &\,-\,& x_4 &=& 0 \\
\end{alignat*}
\begin{subactivity}
Find its solution set (a subspace of \(\IR^4\)).
\end{subactivity}
\begin{subactivity}
Rewrite this solution space in the form \[\setBuilder{ a \begin{bmatrix} \unknown \\ \unknown \\ \unknown \\ \unknown\end{bmatrix} + b \begin{bmatrix} \unknown \\ \unknown \\ \unknown \\ \unknown \end{bmatrix} }{a,b \in \IR}.\]
\end{subactivity}
\end{activity}

\begin{fact}
  The coefficients of the free variables in the solution set of a linear system
  always yield linearly independent vectors.

  \vspace{1em}

  Thus if
  \[
    \setBuilder{
      a \begin{bmatrix} 4 \\ 1 \\ 0 \\ 0\end{bmatrix} +
      b \begin{bmatrix} -3 \\ 0 \\ -2 \\ 1 \end{bmatrix}
    }{
      a,b \in \IR
    }
  \]
  is the solution space for a homoegeneous system, then
  \[
    \setList{
      \begin{bmatrix} 4 \\ 1 \\ 0 \\ 0\end{bmatrix},
      \begin{bmatrix} -3 \\ 0 \\ -2 \\ 1 \end{bmatrix}
    }
  \]
  is a basis for the solution space.
\end{fact}

\begin{activity}{10}
Consider the homogeneous system of equations
\begin{alignat*}{5}
x_1&\,-\,&3x_2&\,+\,& 2x_3&\,\,&  &=& 0 \\
2x_1&\,-\,&6x_2&\,+\,&4x_3 &\,+\,&3 x_4 &=& 0 \\
-2x_1&\,+\,&6x_2&\,-\,&4x_3 &\,-\,&4 x_4 &=& 0 \\
\end{alignat*}

Find a basis for its solution space.
\end{activity}



\end{applicationActivities}
